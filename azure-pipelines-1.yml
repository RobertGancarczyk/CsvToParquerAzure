# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

resources:
  - repo: self

trigger:
  - master

variables:
  databricks-host: 'https://adb-6120026223134701.1.azuredatabricks.net'
  notebook-folder: '/Shared/'
  cluster-id: '1117-220543-haze541'
  notebook-name: 'CsvToParquerAzure'

steps:
- task: UsePythonVersion@0
  displayName: 'Use Python 3.7'
  inputs:
    versionSpec: 3.7
- task: configuredatabricks@0
  inputs:
    url: $(databricks-host)
    token: $(databricks-token)
  displayName: 'Configure Databrick'

- task: deploynotebooks@0
  inputs:
    notebooksFolderPath: '/$(notebook-name).py'
    workspaceFolder: '/Shared'

#- script: |
#    pip install databricks-cli
#  displayName: 'Install databricks-cli'

#- script: |
#   databricks workspace import_dir $(notebook-folder) -o
#  env:
#    DATABRICKS_TOKEN: $(databricks-token)
#    DATABRICKS_HOST: $(databricks-host)

